{
 "metadata": {
  "name": "data_wrangling"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%load_ext autoreload\n",
      "#%autoreload 2\n",
      "import sys\n",
      "sys.path.append('C:\\\\Users\\\\Tyler\\\\.ipython\\\\edge-analysis')\n",
      "from scipy.cluster import vq\n",
      "import numpy as np\n",
      "import json\n",
      "from collections import defaultdict, namedtuple\n",
      "from operator import itemgetter\n",
      "import cStringIO\n",
      "import scipy\n",
      "from scipy.signal import butter, filtfilt\n",
      "\n",
      "import HMM.myBigQuery as myBQ\n",
      "from HMM.myBigQuery import getBody\n",
      "from HMM.myBigQuery import httpGoogle\n",
      "from HMM.myBigQuery import getSchemaFields\n",
      "\n",
      "from HMM.myBigQuery import loadTableFromCSV\n",
      "from HMM.myBigQuery import queryTableData\n",
      "from HMM.myBigQuery import queryGoogle\n",
      "\n",
      "from datetime import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_codebook(args):\n",
      "    features, size, i = args\n",
      "    \n",
      "    import scipy.cluster as cluster\n",
      "    #left = c.vq.kmeans(features[0], size)\n",
      "    #right = c.vq.kmeans(features[1], size)\n",
      "    #return (left, right)\n",
      "    cdbk = cluster.vq.kmeans(features, size)\n",
      "    return cdbk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFeatures(table_name, sensors=None, task=None, hand=None, order=None, limit=0, keys=None, asdict=False):\n",
      "    '''Query BQ for data from table_name based on SQL query entries given above. can return as dict or \n",
      "tuple of keys, array of values. \n",
      "- if limit is <=0, will return all. otherwise will limit to limit. \n",
      "- Order needs to be formatted as the second part of SQL ORDER BY query.'''\n",
      "    #sensors = sensors if sensors else getSensors(table_name)\n",
      "\n",
      "    sensorquery = qSensors(table_name, sensors, task, hand, keys, order, limit)\n",
      "    print sensorquery\n",
      "    results = queryGoogle(sensorquery)\n",
      "    \n",
      "    if asdict: #Return data as {key:np array, key:np.array ...}\n",
      "        hugedict={}\n",
      "        for row in results['rows']:\n",
      "            #If this ID is not a key in the dict, add it\n",
      "            if row['f'][0]['v'] not in hugedict.keys(): hugedict[row['f'][0]['v']] = []\n",
      "            #Regardless, append these values to that list   \n",
      "            hugedict[row['f'][0]['v']].append( [float(vals['v']) for vals in row['f'][1:] ])\n",
      "            \n",
      "        for k, v in hugedict.iteritems():\n",
      "            hugedict[k] = np.array(v)#better/faster way?\n",
      "            \n",
      "        return hugedict\n",
      "        \n",
      "    else: #return tuple of [key, key...], [mxn raw data]\n",
      "        ids = [] #to hold the id corresponding to each timepoint\n",
      "        values = [] #to hold the raw data\n",
      "        for row in results['rows']:\n",
      "            ids.append(row['f'][0]['v'])\n",
      "            values.append([float(vals['v']) for vals in row['f'][1:] ])\n",
      "                \n",
      "        return np.array(ids), np.array(values)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def qSensors(table_name, sensors=None, task=None, hand=None, keys=None, order=None, limit=0):\n",
      "    '''Format a SQL querey to BigQuery based on info about table'''\n",
      "    sensors = sensors if sensors else getSensors(table_name) \n",
      "\n",
      "    SELECT = \"SELECT key, \"+(', '.join( [sensor for sensor in sensors] ))\n",
      "    \n",
      "    FROM = (\" FROM [data.\"+ table_name +\"] \")\n",
      "    \n",
      "    wh = []\n",
      "    if task: wh.append(\"task='%s' \"%task)\n",
      "    if hand: wh.append(\"hand='%s' \"%hand)\n",
      "    wh = 'AND '.join(wh)\n",
      "    WHERE = \"WHERE \"+ wh if wh else ''\n",
      "    \n",
      "    if keys: WHERE = WHERE + \"AND (key='\"+\"' OR key='\".join(keys)+ \"') \"\n",
      "    \n",
      "    ORDER = \" ORDER BY \"+str(order) if order else ''\n",
      "    LIMIT = \" LIMIT \"+str(int(limit)) if limit>0 else ''\n",
      "    \n",
      "    return SELECT + FROM + WHERE + ORDER + LIMIT\n",
      "\n",
      "#sensors = ['QgL', 'FgL', 'QgR', 'FgR']\n",
      "#print qSensors('timdata', sensors=['QgL','FgL'], hand='left', task='suturing', limit=1000, keys=['pegtransfer_1','pegtransfer_2','pegtransfer_3'], order='key, Time')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SELECT key, QgL, FgL FROM [data.timdata] WHERE task='suturing' AND hand='left' AND (key='pegtransfer_1' OR key='pegtransfer_2' OR key='pegtransfer_3')  ORDER BY key, Time LIMIT 1000\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def upload_features(features, date, dataset, hand=None, task=None, tablename=None):\n",
      "    data = cStringIO.StringIO()\n",
      "    fields = myBQ.getSchemaFields(tablename)\n",
      "    for k, v in features.iteritems():\n",
      "        for row in v:\n",
      "            data.write('{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12}\\n'.format(k, row[0], \n",
      "                    row[1], row[2], row[3], row[4], row[5], row[6], row[7], date, dataset, hand, task))\n",
      "                       \n",
      "    body = myBQ.getBody(data.getvalue(), fields, tablename, 'data'\n",
      "                            , createDisposition='CREATE_IF_NEEDED'\n",
      "                            , writeDisposition='WRITE_APPEND')\n",
      "    myBQ.loadTableFromCSV(body)\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def upload_codebook(left, right, dataset, cdbkfeat, task, distL, distR):\n",
      "    data = cStringIO.StringIO()\n",
      "    fields = myBQ.getSchemaFields('codebooks')  \n",
      "    #dataset, date, hand, task, features, distortion, jsoncdbk\n",
      "    data.write('{0},{1},{2},{3},{4},{5},\"{6}\"\\n'.format(dataset, '10-OCT-2012 1:33', 'left',  task, cdbkfeat, distL, json.dumps(left[0].tolist())))   \n",
      "    data.write('{0},{1},{2},{3},{4},{5},\"{6}\"\\n'.format(dataset, '10-OCT-2012 1:33', 'right', task, cdbkfeat, distR, json.dumps(right[0].tolist())))\n",
      "\n",
      "    body = myBQ.getBody(data.getvalue(), fields, 'codebooks', 'data'\n",
      "                              , createDisposition='CREATE_IF_NEEDED'\n",
      "                              , writeDisposition='WRITE_APPEND')\n",
      "    myBQ.loadTableFromCSV(body)\n",
      "    \n",
      "#upload_codebook(min(results[0], key=itemgetter(1)), min(results[1], key=itemgetter(1)))\n",
      "#upload_codebook(cdbkL,cdbkR, dataset, cdbkfeat, task, 0.0401127109316, 0.0396742994943)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#download codebook from bigquery\n",
      "def download_codebook(date):\n",
      "    qs = \"SELECT dataset, task, json FROM data.codebooks WHERE date ='{0}'\".format('10-OCT-2012 1:33')\n",
      "    data = queryGoogle(qs)\n",
      "    \n",
      "    cdbkL = data['rows'][0]['f'][2]['v']\n",
      "    cdbkR = data['rows'][1]['f'][2]['v'] \n",
      "    cdbkL = np.array(json.loads(cdbkL))\n",
      "    cdbkR = np.array(json.loads(cdbkR))\n",
      "    \n",
      "    dataset = str(data['rows'][0]['f'][0]['v'])\n",
      "    task = str(data['rows'][0]['f'][1]['v'] )\n",
      "        \n",
      "    return cdbkL, cdbkR, dataset, task\n",
      "\n",
      "#cdbkL, cdbkR, dataset, task = download_codebook('10-OCT-2012 1:33')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def size_codebook(task):\n",
      "    if task in ['cutting']: return 67\n",
      "    if task in ['suturing']: return 70\n",
      "    if task in ['pegtransfer']: return 57\n",
      "    return 70"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def codebookApply(features, codebook):\n",
      "    '''\n",
      "    returns the code and distance for the codebook\n",
      "    '''\n",
      "    return vq.vq(features, codebook)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def floats(s):\n",
      "    try:\n",
      "        return float(s)\n",
      "    except Exception as e:\n",
      "        return s\n",
      "        #print 'error :', e\n",
      "        #return np.NaN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getSensors(table_name):\n",
      "    fields = json.loads(getSchemaFields(table_name))\n",
      "    sensors =  [field['name'] for field in fields][4:]\n",
      "    return sensors\n",
      "\n",
      "#print getSensors('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTasks(table_name):\n",
      "    tasks = queryGoogle(\"SELECT task from data.{0} GROUP BY task\".format(table_name))\n",
      "    return [task['f'][0]['v'] for task in tasks['rows']]\n",
      "\n",
      "#print getTasks('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Utilities"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Legacy Code from the Ancient Times"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##query to get Quantiles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "def qQuantiles(sensor, table_name, task): \n",
      "    return \"SELECT QUANTILES({0}, 1000) as q{0} FROM [data.{1}] WHERE task=='{2}'\".format(sensor, table_name, task)\n",
      "z='''\n",
      "left = ['QgL', 'FgL']\n",
      "right = ['QgR', 'FgR'] \n",
      "sensors = ['QgL', 'FgL', 'QgR', 'FgR']\n",
      "d =  {sensor: queryGoogle(qQuantiles(sensor, 'timdata', 'suturing')) for sensor in sensors}\n",
      "print d\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def qThresholdSchema(task, table_name):\n",
      "    sensors = getSensors(table_name)\n",
      "    fields = ', '.join(sensors)\n",
      "    return \"SELECT threshold, task, {0} FROM data.schemata WHERE task=='{1}' AND table_name=='{2}'\".format(fields, task, table_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getThresholds(table_name, dataset=None, task_type=None):\n",
      "    dataset = dataset if dataset else table_name\n",
      "\n",
      "    thresholds = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
      "    #data = queryTableData('data', 'thresholds')\n",
      "    qs = \"SELECT task, table_name, threshold, sensor_name, sensor_value FROM data.thresholds WHERE table_name='{0}'\".format(dataset)\n",
      "    data = queryGoogle(qs)\n",
      "    for row in data['rows']:\n",
      "        cells = row['f']\n",
      "        task = 'pegtransfer' if cells[0]['v']=='PegTx' else cells[0]['v'].lower()\n",
      "        ttype = cells[2]['v']\n",
      "        sensor = cells[3]['v']\n",
      "        thresholds[task][sensor][ttype] = cells[4]['v']\n",
      "    \n",
      "    if task_type:\n",
      "        return thresholds.get(task_type, 'ERROR: task not found')\n",
      "    \n",
      "    return thresholds\n",
      "\n",
      "\n",
      "#print getThresholds('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createThresholdsTable(table_name):\n",
      "    data = createThresholds(table_name)\n",
      "    fields = getSchemaFields('thresholds')       \n",
      "    body = getBody(data.getvalue(), fields, 'thresholds', 'data'\n",
      "                               , createDisposition='CREATE_IF_NEEDED'\n",
      "                               , writeDisposition='WRITE_APPEND')\n",
      "    loadTableFromCSV(body)\n",
      "#createThresholdsTable('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createThresholds(table_name):\n",
      "    sensors = getSensors(table_name)\n",
      "    thresholds = cStringIO.StringIO()\n",
      "    for task in getTasks(table_name):\n",
      "        #create dict of sensor: quantiles binned into 1000 bins\n",
      "        quantiles = {sensor: queryGoogle(qQuantiles(sensor, table_name, task)) for sensor in sensors}\n",
      "        for field in permil._fields: #permil._fields is essentially a dict of threshold names and bin value\n",
      "            p = getattr(permil, field) #p is going to be one of (4, 19 979 994)\n",
      "            for sensor in sensors:\n",
      "                thresholds.write('{0},{1},{2},{3},{4}\\n'.format(task, table_name, field, sensor, quantiles[sensor]['rows'][p]['f'][0]['v']))\n",
      "        #thresholds = cStringIO.StringIO(open('thresholds.csv').read()) #to hardcode thresholds from matlab\n",
      "    return thresholds\n",
      "\n",
      "#print createThresholds('timdataMatlab').getvalue()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##query to remove outliers based on thresholds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quantiles = namedtuple('quantiles', 'lowOutlier lowNorm highNorm highOutlier')\n",
      "permil = quantiles(4, 19, 979, 994)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def qOutliers(task, table_name, thresholds=None, limit=0, sensors=None):\n",
      "    sensors = sensors if sensors else getSensors(table_name) \n",
      "    SELECT = (\"SELECT key, \")   \n",
      "    select = [] \n",
      "    FROM = (\" FROM [data.\"+ table_name +\"] \")\n",
      "    WHERE = (\"WHERE task='{0}' AND \".format(task))\n",
      "    LIMIT = \" LIMIT \"+str(int(limit))\n",
      "    where = []\n",
      "    for sensor in sensors:\n",
      "        select.append(sensor)\n",
      "        if abs(float(thresholds[task][sensor]['lowNorm']) - float(thresholds[task][sensor]['highNorm'])) > 0.01 or \\\n",
      "           abs(float(thresholds[task][sensor]['lowOutlier']) - float(thresholds[task][sensor]['highOutlier'])) > 0.01:\n",
      "            where.append(\"({0} > {1} AND {0} < {2})\\n\".format(sensor, thresholds[task][sensor]['lowOutlier'], thresholds[task][sensor]['highOutlier']))\n",
      "    #if limit  > 0:  return SELECT + (', '.join(select)) + FROM + WHERE + ' AND '.join(where) + LIMIT\n",
      "    return SELECT + (', '.join(select)) + FROM + WHERE + ' AND '.join(where) + (LIMIT if limit > 0 else '')\n",
      "\n",
      "\n",
      "#sensors = ['QgL', 'FgL', 'QgR', 'FgR']\n",
      "#print qOutliers('suturing', 'timdata', getThresholds('timdata', 'timdataMatlab'), sensors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "def getFeaturesOld(table_name, task, limit, dataset=None, sensors=None):\n",
      "\n",
      "    sensors = sensors if sensors else getSensors(table_name)\n",
      "    dataset = dataset if dataset else table_name\n",
      "    print 'table_name=', table_name, ' task=',task, ' dataset=', dataset, ' sensors=', sensors\n",
      "    thresholds = {task: getThresholds(table_name, dataset, task)}\n",
      "    outliers = qOutliers(task, table_name, thresholds, limit, sensors)\n",
      "    results = queryGoogle(sensorquery)\n",
      "\n",
      "    return (np.array([[floats(field['v']) for field in row['f']] for row in results['rows']]), thresholds[task])\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}