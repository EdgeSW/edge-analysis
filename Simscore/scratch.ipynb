{
 "metadata": {
  "name": "scratch"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os\n",
      "sys.path.append('C:\\\\Users\\\\Tyler\\\\.ipython\\\\edge-analysis')\n",
      "\n",
      "import boto, time, json, pprint\n",
      "from datetime import datetime, timedelta\n",
      "import numpy as np\n",
      "\n",
      "import helpers\n",
      "import fetch.myS3 as myS3\n",
      "import fetch.mySQS as mySQS\n",
      "import Simscore.validity_metrics as vm\n",
      "from fetch.aws import aws_ak, aws_sk\n",
      "from Simscore.report.configuration import isClipTask   \n",
      "import Simscore.report.validate as validate\n",
      "conn = boto.connect_s3(aws_ak, aws_sk)\n",
      "bucket = conn.get_bucket('incoming-simscore-org')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unit_files = [#Name, Dead, OOR, NaN\n",
      "(\t\"edge6/2013/01/31.00.42.06.392.3.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge10/2013/01/22.18.09.46.209.0.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge10/2013/01/26.16.02.02.365.0.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge3/2013/01/18.18.54.37.336.1.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge6/2013/01/31.00.50.47.392.2.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge10/2013/01/24.17.05.48.389.2.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge10/2013/01/10.15.22.12.389.2.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge6/2013/01/31.00.46.29.392.2.txt\"\t,\t[]\t,\t[]\t,\t[]\t),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "(\t\"edge7/2012/12/07.15.37.27.109.2.txt\"\t,\t[]\t,\t[\"ThG_L\", \"Fg_L\", \"ThG_R\"]\t,\t[]\t),\n",
      "(\t\"edge9/2012/11/29.01.24.15.251.1.txt\"\t,\t[]\t,\t[\"Fg_L\", \"Fg_R\"]\t,\t[]\t),\n",
      "(\t\"edge9/2012/11/29.01.22.22.251.3.txt\"\t,\t[]\t,\t[\"Fg_L\", \"Lin_R\"]\t,\t[]\t),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "(\t\"edge8/2012/12/06.18.40.18.109.1.txt\"\t,\t[\"Fg_L\"]\t,\t[]\t,\t[]\t),\n",
      "(\t\"edge8/2012/12/06.18.39.40.109.1.txt\"\t,\t[\"Fg_L\"]\t,\t[]\t,\t[]\t),\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "(\t\"edge6/2012/11/05.18.59.45.340.1.txt\"\t,\t[]\t,\t[\"Fg_L\"]\t,\t[\"Fg_R\"]\t),\n",
      "(\t\"edge6/2012/11/05.18.46.23.340.0.txt\"\t,\t[]\t,\t[\"Fg_L\"]\t,\t[\"Fg_R\"]\t),\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "(\t\"edge6/2012/11/05.19.24.12.340.2.txt\"\t,\t[\"Fg_L\", \"Rot_L\"]\t,\t[\"Fg_L\", \"ThG_L\"]\t,\t[]\t),\n",
      "(\t\"edge1/2012/10/08.15.22.48.323.1.txt\"\t,\t[\"Fg_L\"]\t,\t[\"Fg_L\"]\t,\t[]\t),\n",
      "(\t\"edge6/2013/01/25.21.33.58.393.0.txt\"\t,\t[\"Rot_L,\" \"ThG_L\"]\t,\t[\"ThG_L\"]\t,\t[]\t),\n",
      "(\t\"edge2/2013/01/09.16.06.18.378.3.txt\"\t,\t[\"Fg_R\"]\t,\t[\"Rot_L\"]\t,\t[]\t),\n",
      "(\t\"edge2/2012/12/03.20.12.46.109.3.txt\"\t,\t[\"Fg_R\"]\t,\t[\"Lin_R\"]\t,\t[]\t),\n",
      "(\t\"edge6/2013/01/25.22.30.14.312.0.txt\"\t,\t[\"Fg_R\", \"ThG_R\", \"Rot_R\"]\t,\t[\"ThG_R\"]\t,\t[]\t)\n",
      "\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_deads = []\n",
      "for test in unit_files:\n",
      "    try:\n",
      "        data, meta = myS3.getData(bucket, test[0], labeled=True)\n",
      "        minmax = validate.findMinMax(data)\n",
      "        \n",
      "        new_dead = validate.findDeadSensors(data, minmax, meta['TaskId'], meta['IsPracticeTest'])\n",
      "        old_dead = validate.oldFindDeadSensor(validate.findMinMax(data), isClipTask(test[0]))\n",
      "        #oors = validate.findOutOfRange(minmax)\n",
      "        \n",
      "        print 'verifying',test[0]\n",
      "        print 'Dead sensors should be:', test[1]\n",
      "        print 'New method caught:', new_dead\n",
      "        print 'Old method caught:', old_dead\n",
      "        print \n",
      "    except Exception as e:\n",
      "        print e\n",
      "        print 'error in',fn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "verifying edge6/2013/01/31.00.42.06.392.3.txt\n",
        "Dead sensors should be: []\n",
        "New method caught: ['Fg_L']\n",
        "Old method caught: ['Fg_L']\n",
        "\n",
        "verifying"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " edge10/2013/01/22.18.09.46.209.0.txt\n",
        "Dead sensors should be: []\n",
        "New method caught: []\n",
        "Old method caught: []\n",
        "\n",
        "verifying"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-b57ecc7fee0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munit_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyS3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mminmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindMinMax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\Tyler\\.ipython\\edge-analysis\\fetch\\myS3.py\u001b[0m in \u001b[0;36mgetData\u001b[1;34m(bucket, filename, labeled)\u001b[0m\n\u001b[0;32m     43\u001b[0m     returned with an associated dtype or not (see dataParse below)'''\n\u001b[0;32m     44\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Please provide a bucket or S3 connection instance'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetRawData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetMetaData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\Tyler\\.ipython\\edge-analysis\\fetch\\myS3.py\u001b[0m in \u001b[0;36mgetRawData\u001b[1;34m(bucket, filename, labeled)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mbKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbKey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"File not found on S3\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanRaw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbKey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\Tyler\\.ipython\\edge-analysis\\fetch\\myS3.py\u001b[0m in \u001b[0;36mcleanRaw\u001b[1;34m(bKey)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;34m'''Removes header, cleans each line of extra whitespace'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcStringIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mbKey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_contents_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0mtxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#seeks to start of file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\boto\\s3\\key.pyc\u001b[0m in \u001b[0;36mget_contents_to_file\u001b[1;34m(self, fp, headers, cb, num_cb, torrent, version_id, res_download_handler, response_headers)\u001b[0m\n\u001b[0;32m   1364\u001b[0m                 self.get_file(fp, headers, cb, num_cb, torrent=torrent,\n\u001b[0;32m   1365\u001b[0m                               \u001b[0mversion_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1366\u001b[1;33m                               response_headers=response_headers)\n\u001b[0m\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m     def get_contents_to_filename(self, filename, headers=None,\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\boto\\s3\\key.pyc\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(self, fp, headers, cb, num_cb, torrent, version_id, override_num_retries, response_headers)\u001b[0m\n\u001b[0;32m   1262\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m             \u001b[0mcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1264\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1265\u001b[0m             \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[0mdata_len\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\boto\\s3\\key.pyc\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBufferSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\boto\\connection.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_response\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mhttplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPResponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\socket.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;31m# fragmentation issues on many platforms.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\ssl.pyc\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m    239\u001b[0m                     \u001b[1;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                     self.__class__)\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\ssl.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " edge10/2013/01/26.16.02.02.365.0.txt\n",
        "Dead sensors should be: []\n",
        "New method caught: []\n",
        "Old method caught: []\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "import time\n",
      "for filename in biglist:\n",
      "    try:\n",
      "        data, meta = myS3.getData(bucket, filename, labeled=True)\n",
      "        minmax = validate.findMinMax(data)\n",
      "        \n",
      "        new_dead = findDeadSensors(data, minmax, meta['TaskId'], meta['IsPracticeTest'])\n",
      "        old_dead = validate.findDeadSensor(validate.findMinMax(data), isClipTask(filename))\n",
      "        \n",
      "        if filename[-5:]=='2.txt':\n",
      "            print filename,old_dead, new_dead\n",
      "        time.sleep(0.1)\n",
      "    except Exception as e:\n",
      "        print e\n",
      "        print filename\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "\"\\nimport time\\nfor filename in biglist:\\n    try:\\n        data, meta = myS3.getData(bucket, filename, labeled=True)\\n        minmax = validate.findMinMax(data)\\n        \\n        new_dead = findDeadSensors(data, minmax, meta['TaskId'], meta['IsPracticeTest'])\\n        old_dead = validate.findDeadSensor(validate.findMinMax(data), isClipTask(filename))\\n        \\n        if filename[-5:]=='2.txt':\\n            print filename,old_dead, new_dead\\n        time.sleep(0.1)\\n    except Exception as e:\\n        print e\\n        print filename\\n\""
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "biglist = myS3.getFilesBetween(datetime.utcnow()-timedelta(days=160), datetime.utcnow(), bucket, True)\n",
      "print len(biglist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "586\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lists_contain_same(lis1, lis2):\n",
      "    if lis1 == lis2:\n",
      "        return True\n",
      "    if len(lis1)!=len(lis2):\n",
      "        return False\n",
      "    for item in lis1:\n",
      "        if item not in lis2:\n",
      "            return False\n",
      "    for item in lis2:\n",
      "        if item not in lis1:\n",
      "            return False\n",
      "    return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "\n",
      "filestoredo = []\n",
      "\n",
      "for filename in biglist:\n",
      "    try:\n",
      "        data, meta = myS3.getData(bucket, filename, labeled=True)\n",
      "        minmax = validate.findMinMax(data)\n",
      "        \n",
      "        old_oors = validate.oldFindOutOfRange(minmax)\n",
      "        old_deads = validate.oldFindDeadSensor(minmax, isClipTask(filename))\n",
      "        js = vm.summary_metrics(meta, data, conn)\n",
      "        js = vm.data_metrics_append(js, data, filename)\n",
      "        new_oors = js['OutOfRange']\n",
      "        new_deads = js['DeadSensors']\n",
      "        ignore = js['IgnoreErrors']\n",
      "        \n",
      "        _oors = []\n",
      "        _deads = []\n",
      "        for oor in new_oors:\n",
      "            if oor not in old_oors and 'OutOfRange' not in ignore.get(oor, []):\n",
      "                _oors.append(oor)\n",
      "                if filename not in filestoredo: filestoredo.append(filename)\n",
      "        for dead in new_deads:\n",
      "            if dead not in old_deads and 'DeadSensors' not in ignore.get(dead, []):\n",
      "                _deads.append(dead)\n",
      "                if filename not in filestoredo: filestoredo.append(filename)\n",
      "                    \n",
      "        if js['TaskType'] == 1: filestoredo.append(filename)\n",
      "            \n",
      "        if _oors or _deads: print filename, _oors, _deads\n",
      "        time.sleep(0.1)\n",
      "    except Exception as e:\n",
      "        print e, filename\n",
      "        \n",
      "print filestoredo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "\"import time\\nimport helpers\\nfilestoredo = []\\n\\nfor filename in biglist:\\n    try:\\n        data, meta = myS3.getData(bucket, filename, labeled=True)\\n        minmax = validate.findMinMax(data)\\n        \\n        old_oors = validate.oldFindOutOfRange(minmax)\\n        old_deads = validate.oldFindDeadSensor(minmax, isClipTask(filename))\\n        js = vm.summary_metrics(meta, data, conn)\\n        js = vm.data_metrics_append(js, data, filename)\\n        new_oors = js['OutOfRange']\\n        new_deads = js['DeadSensors']\\n        ignore = js['IgnoreErrors']\\n        \\n        _oors = []\\n        _deads = []\\n        for oor in new_oors:\\n            if oor not in old_oors and 'OutOfRange' not in ignore.get(oor, []):\\n                _oors.append(oor)\\n                if filename not in filestoredo: filestoredo.append(filename)\\n        for dead in new_deads:\\n            if dead not in old_deads and 'DeadSensors' not in ignore.get(dead, []):\\n                _deads.append(dead)\\n                if filename not in filestoredo: filestoredo.append(filename)\\n                    \\n        if js['TaskType'] == 1: filestoredo.append(filename)\\n            \\n        if _oors or _deads: print filename, _oors, _deads\\n        time.sleep(0.1)\\n    except Exception as e:\\n        print e, filename\\n        \\nprint filestoredo\""
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(filestoredo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "230"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fetch.mySQS as mySQS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from aws import aws_ak, aws_sk\n",
      "from boto.sqs.message import Message\n",
      "'''Define Connections'''\n",
      "sqs_conn = boto.connect_sqs(aws_ak, aws_sk)\n",
      "q = sqs_conn.get_queue('Files2Ship')\n",
      "comq = sqs_conn.get_queue('EdgeFiles2Process')\n",
      "#Connect to ses\n",
      "ses_conn = boto.connect_ses(aws_ak, aws_sk)\n",
      "#Connect to SimpleDB\n",
      "sdb_conn = boto.connect_sdb(aws_ak, aws_sk)\n",
      "sdb_domain = sdb_conn.get_domain('ProcessedEdgeFiles')\n",
      "\n",
      "mySQS.append_list_to_queue(filestoredo, comq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}