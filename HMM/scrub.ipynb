{
 "metadata": {
  "name": "scrub"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy.signal import butter, filtfilt\n",
      "from scipy import stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fixOffset(npdata, offset=1e8):    \n",
      "    '''cleans up data with large, instantaneous offsets (intended for Rot)'''\n",
      "    ndata = np.copy(npdata -npdata[0])\n",
      "    diffs = np.diff(ndata)\n",
      "    idxs = np.nonzero(abs(diffs) > offset)\n",
      "    \n",
      "    for idx in idxs[0]:\n",
      "        ndata[idx+1:] = ndata[idx+1:] - diffs[idx]\n",
      "        \n",
      "    return ndata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def arcLength(d, th):\n",
      "    '''d = 3xn data (x, y, z) converted to arc length.\n",
      "Movement below th cut to zero, data should be filtered prior'''\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def holo(data, h):\n",
      "    '''Calculate time derivative according to holoborodko's 11th order method\n",
      "http://www.holoborodko.com/pavel/numerical-methods/numerical-derivative/smooth-low-noise-differentiators/\n",
      "f = the data to be differentiated\n",
      "h = the step size, or change in time, between each sample'''\n",
      "    \n",
      "    df = np.zeros(len(data)) \n",
      "    s = 5 #depends on order of holoborodko\n",
      "    \n",
      "    pad1 = [2*data[0]]*s - data[s:0:-1]\n",
      "    pad2 = [2*data[-1]]*s - data[-2:-(s+2):-1]\n",
      "    f = np.append(np.append(pad1, data),pad2)\n",
      "    \n",
      "    for i in range(s, len(data)+s):\n",
      "        #Real 11th order Holoborodko\n",
      "        df[i-s] = (322*(f[i+1]-f[i-1])+256*(f[i+2]-f[i-2])+39*(f[i+3]-f[i-3])\n",
      "            -32*(f[i+4]-f[i-4])-11*(f[i+5]-f[i-5]) ) / (1536*h)\n",
      "  \n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lowpass_butter(input_sig=None, N=10, Wn=5, Fs=None, filter_saftey_margin=1.15):\n",
      "    '''N = filter order, Wn is cutoff frequency, Fs is sampling frequency, safety_marign multiplies \n",
      "cutoff frequency to prevent signal wipeout'''\n",
      "    b, a = scipy.signal.iirfilter(N, filter_saftey_margin*Wn/(Fs/2), btype='low', ftype='butter')\n",
      "    return scipy.signal.filtfilt(b, a, input_sig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def butter_filter(features, snsrs_edge, task, in_place=True):\n",
      "    '''Filters array of data by column using 10th order Butterworth filter and Fcutoffs computed\n",
      "in Tim's Thesis. Can run in place or generate new array. \n",
      "N = filter order, Wn is cutoff frequency, Fs is sampling frequency, safety_marign multiplies \n",
      "cutoff frequency to prevent signal wipeout'''\n",
      "    N = 10\n",
      "    filter_saftey_margin = 1.15\n",
      "    Fs = 30.0 \n",
      "    if not in_place: featfilt = np.zeros(features.shape) #for creating new variable\n",
      "    assert type(snsrs_edge) == list, \"snsrs_edge must be type list\"\n",
      "    \n",
      "    for col in range(len(snsrs_edge)):\n",
      "        #TESTED, CHECKS OUT\n",
      "        Wn = fcth[snsrs_edge[col]][tasks[task]] #Get cutoff frequency\n",
      "        b, a = scipy.signal.iirfilter(N, filter_saftey_margin*Wn/(Fs/2), btype='low', ftype='butter')\n",
      "        \n",
      "        if in_place: # For in-place calculations\n",
      "            if len(snsrs_edge) == 1: features[:] = scipy.signal.filtfilt(b, a, features[:].astype(float))\n",
      "            else: features[:,col] = scipy.signal.filtfilt(b, a, features[:,col].astype(float))\n",
      "            \n",
      "        else: # For new copy of features:\n",
      "            if len(snsrs_edge) == 1: featfilt[:] = scipy.signal.filtfilt(b, a, features[:].astype(float))\n",
      "            else: featfilt[:,col] = scipy.signal.filtfilt(b, a, features[:,col].astype(float))\n",
      "        \n",
      "    return features if in_place else featfilt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dRtaArctan(dRta):\n",
      "    '''(k\u0019pi/2)arctan(\u0019pi*dQ3/k) where k = 125\u000edeg*sec. See Timk Thesis p32'''\n",
      "    k = 125\n",
      "    return (k*np.pi/2) * np.arctan(np.pi*dRta/k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fix_offset_between_tests(ids, feature):\n",
      "    '''When tests are concatenated to create codebooks, offsets between end and begin of tests create large jumps in \n",
      "Rot values. When dRot is calculated, these will be amplified. This script removes such offsets in prep for derivation'''\n",
      "    #ridx = snsrs_edge.index('Rot')#+1 if first column of features is the testid\n",
      "    for i in range(len(ids)-1):\n",
      "        if ids[i] != ids[i+1]: #if the ID has changed\n",
      "            #print ids[i]\n",
      "            feature[i+1:] = feature[i+1:] - (feature[i+1]-feature[i])\n",
      "            \n",
      "    return feature"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normalize each feature\n",
      "def makeThresholds(feat, pctls=[0.5, 2, 98, 99.5]):\n",
      "    '''Computes percentiles of a given distribution, returned as list\n",
      "feat must be a 1D vector of values, not a 2D array. Need not be sorted.'''\n",
      "    if type(pctls) != list: pctls = list(pctls)\n",
      "    return [stats.scoreatpercentile(feat, p) for p in pctls]\n",
      "  \n",
      "    \n",
      "def findOutliers(feat, lowerpctl, upperpctl):\n",
      "    '''Find all locations where feature contains data that is \n",
      "below lower and above upper'''\n",
      "    return np.where((feat < lowerpctl) | (feat > upperpctl))[0]\n",
      "    \n",
      "def normalize(feat, lowerpctl, upperpctl):\n",
      "    '''Map feature such that [lowerpctl upperpctl] = [-1 1]'''\n",
      "    return (feat - lowerpctl) * (2/ (upperpctl-lowerpctl)) - 1\n",
      "    \n",
      "def normalizeByColumn(features, thresholds):\n",
      "    '''features is mxn np.array of separate features, organized as column vectors. \n",
      "thresholds is list of lists, or array, that is nx4 (lowerOutlier, lowerNorm, upperNorm, upperOutlier)'''\n",
      "    assert features.shape[1] == len(thresholds), 'Num of Features and thresholds do not agree.'\n",
      "    \n",
      "    for col in range(features.shape[1]):\n",
      "        features[:,col] = normalize(features[:,col], thresholds[col][1], thresholds[col][2]) \n",
      "    return features\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def removeAndNormalize(features, thresholds=None):\n",
      "    '''combines all steps of normalization'''\n",
      "    #Find all thresholds\n",
      "    if not thresholds:\n",
      "        thresholds = [makeThresholds(features[:,col]) for col in range(features.shape[1])]\n",
      "        \n",
      "    #Delete all outliers\n",
      "    didx = np.empty(0)\n",
      "    for col in range(features.shape[1]):\n",
      "        didx = np.append(didx, findOutliers(features[:,col], thresholds[col][0], thresholds[col][3]))\n",
      "    #Note to self - doesn't matter for delete if indexes listed multiple times. Thanks, Numpy!\n",
      "    features = np.delete(features, didx, 0) \n",
      "    \n",
      "    #Normalize each feature\n",
      "    features = normalizeByColumn(features, thresholds)\n",
      "        \n",
      "    return features, thresholds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "VQ Encoding, Prep "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def encodeSegments(feat_seg_norm, codebook):\n",
      "    '''encode segments of mxn shape with codebook of sxn size where s \n",
      "is your desired number of codewords from vq'''\n",
      "    encoded_segments = []\n",
      "    \n",
      "    for segment in feat_seg_norm:\n",
      "        encd, distortion = vq.vq(segment, codebook)\n",
      "        encoded_segments.append(encd)\n",
      "    return encoded_segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def zipSegments(segments):   \n",
      "    '''NLTK HMM trainier requires specific input format of \n",
      "encoded features. [[(34,''),(45,'')],[...] ] for example. Tuple is\n",
      "(observed, labeled state) though unsupervised training does not require\n",
      "known labeled state, thus empty string'''\n",
      "    for i in range(len(segments)):\n",
      "        segments[i] = zip(segments[i],['']*len(segments[i]))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Constants, Feature Names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['%Time_V1', 'J1_L', 'J2_L', 'Lin_L', 'Rot_L', 'ThG_L', 'Fg_L', 'J1_R', 'J2_R', 'Lin_R', 'Rot_R', 'ThG_R', 'Fg_R', 'X_L', 'Y_L', 'Z_L', 'X_R', 'Y_R', 'Z_R']\n",
      "tasks = {'pegtransfer': 0, 'pegtx': 0, 'cutting': 1, 'suturing': 2, 'clipapply': 3}\n",
      "features = {}\n",
      "for i in range(len(names)): features[names[i]] = i\n",
      "\n",
      "mvmtth = { 'J1'  : 0.0193\n",
      "\t\t , 'J2'  : 0.0174\n",
      "\t\t , 'Lin' : 0.0\n",
      "\t\t , 'Rot' : 0.0564\n",
      "\t\t , 'ThG' : 0.0733\n",
      "\t\t , 'Fg'  : 0.0363\n",
      "\t\t , 'X'   : 0.00699\n",
      "\t\t , 'Y'   : 0.00565\n",
      "\t\t , 'Z'   : 0.00292 }\n",
      "         \n",
      "fcth = {'J1'  : [1.78, 1.86, 1.63]\n",
      "\t\t , 'J2'  : [1.60, 1.24, 1.24]\n",
      "\t\t , 'Lin' : [5.00, 5.00, 5.00]\n",
      "\t\t , 'Rot' : [5.00, 5.00, 5.00]\n",
      "\t\t , 'ThG' : [3.61, 6.92, 2.54]\n",
      "\t\t , 'Fg'  : [3.05, 6.21, 2.37]\n",
      "\t\t , 'X'   : [1.57, 1.51, 1.24]\n",
      "\t\t , 'Y'   : [1.60, 1.33, 1.51]\n",
      "\t\t , 'Z'   : [1.89, 1.89, 1.60] }\n",
      "\n",
      "gtExp_idxs = {'pegtransfer':[47, 168, 449, 9, 413, 18]\n",
      "              ,'cutting':[545, 247, 289, 520, 543, 290, 203, 222, 198, 523]\n",
      "              ,'suturing':[364, 347, 309, 344, 317, 315, 350, 402]\n",
      "              }\n",
      "gtExp_keys = {'pegtransfer':['pegtransfer_'+str(idx) for idx in gtExp_idxs['pegtransfer'] ]\n",
      "              ,'cutting':['cutting_'+str(idx) for idx in gtExp_idxs['cutting'] ]\n",
      "              ,'suturing':['suturing_'+str(idx) for idx in gtExp_idxs['suturing'] ]\n",
      "              }\n",
      "              "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}